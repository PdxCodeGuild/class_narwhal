# https://auto.gluon.ai/stable/index.html
# https://auto.gluon.ai/stable/tutorials/tabular_prediction/tabular-quickstart.html

import autogluon as ag
from autogluon import TabularPrediction as task

# 0. Should have broken the train dataset into train and test using python.. but did not.

# 1. Definin the training dataset
train_data = task.Dataset(file_path='data/train.csv')

# 2. Set the max sample small to start ie 500 so the program doesnt take time to run the first time
subsample_size = 500  # subsample subset of data for faster demo, try setting this to much larger values
train_data = train_data.sample(n=subsample_size, random_state=0)
print(train_data.head())

# 3. Define the variable of intrest and summarize it
label_column = 'Survived'
print("Summary of class variable: \n", train_data[label_column].describe())

# 4. specifies a folder to store trained models that will be generated by the code
dir = 'trained_models' 

# 5. Train the models and dump the outputs into a folder (uncomment to retrain)
# predictor = task.fit(train_data=train_data, label=label_column, output_directory=dir)

# 6. Need to use the train dataset here to do the prediction so can run stats on the models
test_data = task.Dataset(file_path='data/train.csv')
y_test = test_data[label_column]  # values to predict
test_data_nolab = test_data.drop(labels=[label_column],axis=1)  # delete label column to prove we're not cheating
print(test_data_nolab.head())

# unnecessary, just demonstrates how to load previously-trained predictor from file 
predictor = task.load(dir)  


# 7. Generate predictions
y_pred = predictor.predict(test_data_nolab)
print("Predictions:  ", y_pred)

# 8. Compare actual to predicted - is the model any good?
perf = predictor.evaluate_predictions(y_true=y_test, y_pred=y_pred, auxiliary_metrics=True)

# Stuff I added just for fun
# 9. Show the model leaderboard
print("best model below")
best_model = predictor.get_model_best()
print(best_model) # go look for the pkl file in the trained models folder

# Next steps
# There are 2 ways to go
# 1. Turn the pkl file for the best model into a web api using flask or django and reference the API in the app
# 2. Have the web app use the pkl file directly to generate predictions
